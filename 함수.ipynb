{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 박스플랏\n",
    "def boxplot(df,ncols,nrows): \n",
    "    plt.style.use('seaborn')\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(nrows, ncols, constrained_layout=True)\n",
    "\n",
    "    fig.set_size_inches((20, 100))\n",
    "\n",
    "    for col, ax in zip(df.columns, axs.T.ravel()):\n",
    "        df[[col]].boxplot(ax=ax)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## distplot\n",
    "def dist (df,col_n,row_n):\n",
    "    \n",
    "    plt.rcParams['font.family'] = \"Malgun Gothic\"\n",
    "    plt.rcParams['axes.unicode_minus'] = False # 마이너스숫자 출력처리\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=col_n, nrows=row_n, figsize=(20,row_n*5))\n",
    "\n",
    "    for i, col in enumerate(df.columns[:]):\n",
    "        sns.distplot(df[col], bins=20, ax=ax[int(i/col_n),int(i%col_n)] , color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qqplot(df,ncols,nrows):\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "   \n",
    "    fig, axs = plt.subplots(nrows, ncols, constrained_layout=True)\n",
    "    fig.set_size_inches((50, 80))\n",
    "\n",
    "    for ax, i in zip(axs.ravel(), df):\n",
    "            stats.probplot(df[i], dist=stats.norm, plot=ax)\n",
    "            ax.set_title(str(i))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.light_palette(\"darkgray\", as_cmap = True)\n",
    "sns.set(font=\"Malgun Gothic\",rc = {'figure.figsize':(16,8)})  \n",
    "\n",
    "#pairplot\n",
    "sns.pairplot(x,cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 히트맵\n",
    "colormap = plt.cm.PuBu\n",
    "plt.figure(figsize=(100, 100))\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rc('font', family=\"Malgun Gothic\")\n",
    "plt.title(\"Correlation of Features\", y = 1.05, size = 15)\n",
    "sns.heatmap(x_train_stan.astype(float).corr(), linewidths = 0.1, ,vmax = 1.0, \n",
    "            vmin= -1.0 , square = True, cmap = colormap, linecolor = \"white\", annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 샤피로 테스트\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "def Shapiro(df):\n",
    "    Shapi = []\n",
    "    Shapi.append([col for col in df])\n",
    "    for i in Shapi:\n",
    "        for j in i:\n",
    "            shapiro_test,p_val = shapiro(df[j])\n",
    "            print(j,\"Test-statistics : {}, p-value : {}\". format(shapiro_test,p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 엔더슨 테스트\n",
    "from scipy import stats\n",
    "from scipy.stats import anderson\n",
    "\n",
    "def Anderson(df):\n",
    "    ander = []\n",
    "    ander.append([col for col in df])\n",
    "    for i in ander:\n",
    "        for j in i:\n",
    "            anderson_test = anderson(df[j], dist='norm')\n",
    "            print(j,anderson_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규성 검정을 하나의 함수로\n",
    "from scipy.stats import shapiro, anderson, kstest, jarque_bera, normaltest\n",
    "\n",
    "def normal_test(test_name,x):\n",
    "    normal = []\n",
    "    notnormal = []\n",
    "    if test_name == 'shapiro':\n",
    "        for var in x.columns :\n",
    "            stat, p  = shapiro(x[var].values)\n",
    "            alpha = 0.05\n",
    "            if p > alpha :\n",
    "                normal.append(var)\n",
    "            else :\n",
    "                notnormal.append(var)\n",
    "                \n",
    "    elif test_name == 'anderson':\n",
    "        for var in x.columns :\n",
    "            result  = anderson(x[var].values,dist='norm')\n",
    "            normality = 0\n",
    "            for i in range(len(result.critical_values)):\n",
    "                # sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "                if result.statistic < result.critical_values[i]:\n",
    "                    normality +=1\n",
    "                else :\n",
    "                    normality +=0\n",
    "            if normality > 2.5 :\n",
    "                normal.append(var)\n",
    "            else :\n",
    "                notnormal.append(var)\n",
    "                \n",
    "    elif test_name == 'kstest':\n",
    "        for var in x.columns :\n",
    "            stat,p  = kstest(x[var].values, \"norm\")\n",
    "            alpha = 0.05\n",
    "            if p > alpha :\n",
    "                normal.append(var)\n",
    "            else :\n",
    "                notnormal.append(var)\n",
    "    \n",
    "    elif test_name == 'jarque_bera':\n",
    "        for var in x.columns :\n",
    "            stat,p  = jarque_bera(x[var].values)\n",
    "            alpha = 0.05\n",
    "            if p > alpha :\n",
    "                normal.append(var)\n",
    "            else :\n",
    "                notnormal.append(var)\n",
    "                \n",
    "    elif test_name == 'normaltest':\n",
    "        for var in x.columns :\n",
    "            stat, p  = normaltest(x[var].values)\n",
    "            alpha = 0.05\n",
    "            if p > alpha :\n",
    "                normal.append(var)\n",
    "            else :\n",
    "                notnormal.append(var)\n",
    "    else:\n",
    "        pass\n",
    "    return pd.DataFrame(normal, columns = ['normal']),pd.DataFrame(notnormal, columns = ['notnormal'])\n",
    "# 1) shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H가 1인 경우 이분산성 / H가 0인 경우 등분산\n",
    "from scipy.stats import bartlett\n",
    "import pandas as pd\n",
    "def bartlett_test(df, col, p_value = 0.05, H = 1):\n",
    "    list= []\n",
    "    for i in col:\n",
    "        T, p_val =bartlett(df[df['target']==1][i], df[df['target']==0][i]) \n",
    "        list.append([i, p_val])\n",
    "\n",
    "    list = pd.DataFrame(list, columns = ['변수', 'p_value'])\n",
    "    if H == 1:\n",
    "        a = list[(list['p_value'] < p_value)][['변수', 'p_value']].sort_values('p_value')\n",
    "        return a\n",
    "    else:\n",
    "        a = list[(list['p_value'] >= p_value)][['변수', 'p_value']].sort_values('p_value')\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# VIF 출력을 위한 데이터 프레임 형성\n",
    "vif = pd.DataFrame()\n",
    "\n",
    "# VIF 값과 각 Feature 이름에 대해 설정\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_train_유의.values, i) for i in range(X_train_유의.shape[1])]\n",
    "vif[\"features\"] = X_train_유의.columns \n",
    "\n",
    "# VIF 값이 높은 순으로 정렬\n",
    "vif = vif.sort_values(by=\"VIF Factor\", ascending=False)\n",
    "vif = vif.reset_index().drop(columns='index')\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_feature_selection(X_train, y_train, variables=X_train.columns.tolist() ):\n",
    "    import statsmodels.api as sm\n",
    "    import matplotlib.pyplot as plt\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    y = y_train ## 반응 변수\n",
    "\n",
    "    selected_variables = [] ## 선택된 변수들\n",
    "    sl_enter = 0.05\n",
    "    sl_remove = 0.05\n",
    "    \n",
    "    sv_per_step = [] ## 각 스텝별로 선택된 변수들\n",
    "    adjusted_r_squared = [] ## 각 스텝별 수정된 결정계수\n",
    "    steps = [] ## 스텝\n",
    "    step = 0\n",
    "    while len(variables) > 0:\n",
    "        remainder = list(set(variables) - set(selected_variables))\n",
    "        pval = pd.Series(index=remainder) ## 변수의 p-value\n",
    "        ## 기존에 포함된 변수와 새로운 변수 하나씩 돌아가면서 \n",
    "        ## 선형 모형을 적합한다.\n",
    "        for col in remainder: \n",
    "            X = X_train[selected_variables+[col]]\n",
    "            X = sm.add_constant(X)\n",
    "            model = sm.OLS(y,X).fit(disp=0)\n",
    "            pval[col] = model.pvalues[col]\n",
    "    \n",
    "        min_pval = pval.min()\n",
    "        if min_pval < sl_enter: ## 최소 p-value 값이 기준 값보다 작으면 포함\n",
    "            selected_variables.append(pval.idxmin())\n",
    "            ## 선택된 변수들에대해서\n",
    "            ## 어떤 변수를 제거할지 고른다.\n",
    "            while len(selected_variables) > 0:\n",
    "                selected_X = X_train[selected_variables]\n",
    "                selected_X = sm.add_constant(selected_X)\n",
    "                selected_pval = sm.OLS(y,selected_X).fit(disp=0).pvalues[1:] ## 절편항의 p-value는 뺀다\n",
    "                max_pval = selected_pval.max()\n",
    "                if max_pval >= sl_remove: ## 최대 p-value값이 기준값보다 크거나 같으면 제외\n",
    "                    remove_variable = selected_pval.idxmax()\n",
    "                    selected_variables.remove(remove_variable)\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            step += 1\n",
    "            steps.append(step)\n",
    "            adj_r_squared = sm.OLS(y,sm.add_constant(X_train[selected_variables])).fit(disp=0).rsquared_adj\n",
    "            adjusted_r_squared.append(adj_r_squared)\n",
    "            sv_per_step.append(selected_variables.copy())\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    fig = plt.figure(figsize=(100,10))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    font_size = 15\n",
    "    plt.xticks(steps,[f'step {s}\\n'+'\\n'.join(sv_per_step[i]) for i,s in enumerate(steps)], fontsize=12)\n",
    "    plt.plot(steps,adjusted_r_squared, marker='o')\n",
    "      \n",
    "    plt.ylabel('Adjusted R Squared',fontsize=font_size)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return selected_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IQR 이상치\n",
    "def get_outlier(df=None, column=None, weight=1.5):\n",
    "  # target 값과 상관관계가 높은 열을 우선적으로 진행\n",
    "  quantile_25 = np.percentile(df[column].values, 25)\n",
    "  quantile_75 = np.percentile(df[column].values, 75)\n",
    "\n",
    "  IQR = quantile_75 - quantile_25\n",
    "  IQR_weight = IQR*weight\n",
    "  \n",
    "  lowest = quantile_25 - IQR_weight\n",
    "  highest = quantile_75 + IQR_weight\n",
    "  \n",
    "  outlier_idx = df[column][ (df[column] < lowest) | (df[column] > highest) ].index\n",
    "  return outlier_idx\n",
    "\n",
    "# oulier_idx = get_outlier(df_수치, col, 1.5)\n",
    "# df_수치.drop(oulier_idx , axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ESD이상치\n",
    "def EDS_outlier(df,col,weight=2):\n",
    "    import numpy as np\n",
    "    m = np.mean(df[col])\n",
    "    sd = np.std(df[col])\n",
    "    sd_weight = sd*weight\n",
    "    \n",
    "    lowest = m -sd_weight\n",
    "    highest = m + sd_weight\n",
    "\n",
    "    outlier_idx = df[col][ (df[col] < lowest) | (df[col] > highest) ].index\n",
    "    return outlier_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
